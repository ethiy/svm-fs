{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM et Sélection d'attribut\n",
    "\n",
    "\n",
    "\n",
    "## Variables d'environement\n",
    "\n",
    "Pensez à vérifier les variables d'environement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation linéaire\n",
    "\n",
    "Le but de cette partie est de comparer le SVM linéaire à un autre exemple de classifieur linéaire: le Perceptron. On commence d'abords par rappeler rapidement le principe du Perceptron.\n",
    "\n",
    "### Perceptron\n",
    "\n",
    "L'algorithm du Perceptron date des [travaux de Frank Rosenblatt](http://psycnet.apa.org/record/1959-09865-001). Le but était de modéliser l'action des neurones. Ce modèle va être ensuite utilisé pour contruire des réseaux de neurones complexes et c'est la base de toute les méthodes de Deep Learning. Le modèle donne pour chaque attribut $i \\in \\{1,2, \\dots,d\\}$ de la donnée d'entrée $x = \\begin{pmatrix}x_1\\\\ x_2\\\\ \\vdots \\\\x_d\\end{pmatrix}$ un poids $w_i$. Pour chaque entrée $x$ on lui applique linéairement un vecteur de poids $w = \\begin{pmatrix}w_1\\\\ w_2\\\\ \\vdots \\\\w_d\\end{pmatrix}$ pour lui attribuer un score $s = \\langle w \\vert x\\rangle = \\sum_{i=1,\\dots,d}w_i.x_i$. Suite à ce score obtenu, on prends une décision:\n",
    "* si $s < c \\in \\mathbb{R}$, on choisit la classe $0$;\n",
    "* si $s \\geq c $, on choisit la classe $1$\n",
    "\n",
    "On peut écrire donc ce classifieur autrement:\n",
    "\n",
    "$$D_{perceptron}(x) \\triangleq \\mathbb{1}_{\\langle w \\vert x\\rangle + b \\geq 0}$$\n",
    "\n",
    "où $b = -c$ et $\\mathbb{1}_A(x) = \\begin{cases}1 & , x \\in A\\\\0 & , x \\notin A\\end{cases}$.\n",
    "\n",
    "Si on cherche à rammener les classes à la convention SVM (i.e. $y=\\pm1$), avec une simple transformation affine, on a:\n",
    "$$\\widetilde{D}_{perceptron}(x) \\triangleq 2.\\mathbb{1}_{\\langle w \\vert x \\rangle + b \\geq 0} - 1 = sign(\\langle w \\vert x \\rangle + b \\geq 0)$$\n",
    "\n",
    "### Régression logistique\n",
    "\n",
    "Le modèle de régression logistique est proche des méthodes génératives. Ce Modèle permet juste de donner une relation entre les probabilités par classe et non pas les distributions en elle même:\n",
    "$$ \\ln \\Big( \\frac{p(x \\vert y=1)}{p(x \\vert y=0)}\\Big) = \\langle w \\vert x \\rangle + b$$\n",
    "\n",
    "1. \n",
    "    a. En appliquant la règle de Bayes, montrer que: $$\\ln\\Big(\\frac  {p(y=1\\vert x)}{1-p(y=1\\vert x)}\\Big) = \\ln\\Big(\\frac{p(y=1)}{p(y=0)}\\Big) + b +\\langle w \\vert x \\rangle$$\n",
    "    b. Montrer donc que le décideur de la régression logistique est:\n",
    "$$D_{logistic} = \\sigma(\\tilde b +\\langle w \\vert x \\rangle)$$\n",
    "où: $\\sigma(t) \\triangleq \\frac{1}{1 + e^{-t}} \\quad ,\\forall t \\in \\mathbb{R}$\n",
    "\n",
    "2. Ecrire un code python qui trace les deux fonctions, avec de multiple valeurs de $\\lambda$, $t \\mapsto \\sigma(\\lambda.t)$ et $t \\mapsto \\mathbb{1}_{t \\geq 0}$, dans une même figure. A la lumière de la figure obtenue, discuter les deux fonctions de décisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réponse\n",
    "\n",
    "1. a. \n",
    "\n",
    "   b. \n",
    "\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x = np.linspace(-20, 20, 1000)\n",
    "\n",
    "lambdas = [.1, 1, 10]\n",
    "colors = ['k', 'b', 'r']\n",
    "\n",
    "# Utiliser 'plt' pour tracer les courbes qui correspondent à \\sigma avec les lambda données et la fonctions Heavyside\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison\n",
    "\n",
    "On rappelle ici que le SVM linéaire a pour but de maximiser la marge entre deux classes, contrairement au Perceptron et à la régression logistique. Les problèmes à optimiser ne se ressemble plus.\n",
    "\n",
    "Le but du code, ci-dessous, est d'illustrer cette différence.\n",
    "\n",
    "1. a. Qu'est ce que fait ce bout de code?\n",
    "\n",
    "   b. Commentez le résultat du programme suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "\n",
    "\n",
    "def plot_points(points, ax, color):\n",
    "    ax.scatter(points[:, 0], points[:, 1], c=color)\n",
    "    \n",
    "\n",
    "def plot_dataset(X, Y, ax, colors=['r', 'b']):\n",
    "    for x, col in zip([X[Y==0], X[Y==1]], colors):\n",
    "        plot_points(x, ax, col)\n",
    "        \n",
    "\n",
    "def mesh_from(instances, gap=.2):\n",
    "    return np.meshgrid(\n",
    "        np.arange(X[:, 0].min() - 1, X[:, 0].max() + 1, gap),\n",
    "        np.arange(X[:, 1].min() - 1, X[:, 1].max() + 1, gap),\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_contours(xx, yy, ax, classifier, **parameters):\n",
    "    Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, **parameters)\n",
    "\n",
    "\n",
    "def plot_margin(xx, yy, ax, classifier, **parameters):\n",
    "    Z = np.empty(xx.shape)\n",
    "    for (i, j), value in np.ndenumerate(xx):\n",
    "        Z[i, j] = classifier.decision_function([[value, yy[i, j]]])[0]\n",
    "    ax.contour(xx, yy, Z, [-1.0, 0.0, 1.0], colors='k', linestyles=['dashed', 'solid', 'dashed'])\n",
    "\n",
    "\n",
    "X, Y = sklearn.datasets.make_blobs(n_samples=100, centers=2, random_state=0, cluster_std=0.60)\n",
    "xx, yy = mesh_from(X, .01)\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "for ax, loss , title in zip([ax1, ax2, ax3], ['hinge', 'perceptron', 'log'], ['SVM', 'Perceptron', 'Logistic Regression']):\n",
    "    plot_dataset(X, Y, ax)\n",
    "    model = sklearn.linear_model.SGDClassifier(alpha=0.01, max_iter=100, loss=loss).fit(X, Y)\n",
    "    plot_contours(\n",
    "        xx,\n",
    "        yy,\n",
    "        ax,\n",
    "        model,\n",
    "        cmap=plt.cm.viridis,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    plot_margin(\n",
    "        xx,\n",
    "        yy,\n",
    "        ax,\n",
    "        model\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réponse:\n",
    "\n",
    "1. a. \n",
    "\n",
    "   b. \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pénalisation vs Généralisation\n",
    "\n",
    "1. a. Entraîner des SVM linéaire avec différentes constantes de pénalisation $C$ sur les mêmes données.\n",
    "\n",
    "   b. Tracer la marge selon les valeurs de la constante $C$.\n",
    "   \n",
    "   c. Commenter les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm\n",
    "\n",
    "C = [.01, .1, 1, 10, 100, 1000]\n",
    "\n",
    "f, axes = plt.subplots(1, len(C), sharey=True)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(30)\n",
    "\n",
    "for c, ax in zip(C, list(axes)):\n",
    "    plot_dataset(X, Y, ax)\n",
    "    # Entraîner le modèle\n",
    "    # Tracer les contours et la marge\n",
    "    ax.set_title('C = ' + str(c))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réponse:\n",
    "\n",
    "1. a. \n",
    "\n",
    "   b. \n",
    "   \n",
    "   c.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SVM\n",
    "\n",
    "1. a. Relancer le même code mais cette fois-ci avec le kernel polynomial et le kernel rbf en jouant sur le $gamma$ sur les données suivantes.\n",
    "\n",
    "   b. Commenter les résultats.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = sklearn.datasets.make_circles(n_samples=100, factor=.3, noise=.05)\n",
    "xx, yy = mesh_from(X, .01)\n",
    "\n",
    "gammas = [.5, 1, 2, 3, 4]\n",
    "\n",
    "f, axes = plt.subplots(2, len(gammas), sharey=True)\n",
    "f.set_figheight(10)\n",
    "f.set_figwidth(25)\n",
    "\n",
    "for gamma, ax in zip(gammas, list(axes[0, :])):\n",
    "    plot_dataset(X, Y, ax)\n",
    "    # Entraîner le modèle\n",
    "    # Tracer les contours et la marge\n",
    "    ax.set_title('pol, $\\gamma$ = ' + str(gamma))\n",
    "\n",
    "gammas = [.01, .1, 2, 10, 100]\n",
    "for gamma, ax in zip(gammas, list(axes[1, :])):\n",
    "    plot_dataset(X, Y, ax)\n",
    "    # Entraîner le modèle\n",
    "    # Tracer les contours et la marge\n",
    "    ax.set_title('rbf, $\\gamma$ = ' + str(gamma))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réponse:\n",
    "\n",
    "1. a. \n",
    "\n",
    "   b. \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation croisée\n",
    "\n",
    "### Train-Test split\n",
    "\n",
    "Afin d'estimer le pouvoir de généralisation d'un classifieur, il faut le tester sur de nouvelles instances. On parle de données d'entraînement ou données de tests. En pratique, on garde aussi des données de côtés pour la validation après claibrage entre entrapinements et tests.\n",
    "\n",
    "1. a. En utilisant la fonction [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) fournie par scikit-learn, entraîner un SVM linéaire sur 80% de vos données et tester sur le reste.\n",
    "\n",
    "   b. Répéter l'experience plusieurs fois. Commenter les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "X, Y = sklearn.datasets.make_blobs(n_samples=100, centers=2, random_state=90, cluster_std=0.60)\n",
    "\n",
    "X_train, Y_train = (None, None)\n",
    "X_test, Y_test = (None, None)\n",
    "\n",
    "# Répartir les données en 4/5 de train data et 1/5 de test data\n",
    "\n",
    "C = 1\n",
    "# Entraîner le modèle\n",
    "classifier = None\n",
    "\n",
    "# Tester le modèle entraîné\n",
    "test_score = None\n",
    "\n",
    "print('Test score :', test_score)\n",
    "\n",
    "f, ax = plt.subplots(1, 1)\n",
    "f.set_figheight(10)\n",
    "f.set_figwidth(10)\n",
    "\n",
    "plot_dataset(X_train, Y_train, ax)\n",
    "plot_dataset(X_test, Y_test, ax, ['m', 'g'])\n",
    "xx, yy = mesh_from(X, .01)\n",
    "plot_margin(\n",
    "    xx,\n",
    "    yy,\n",
    "    ax,\n",
    "    model\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche de paramètres\n",
    "\n",
    "L'idée de la validation croisée et que l'on varie les données d'entraînement et de tests de façon à ne pas entraîner sur les mauvaises instances et puis tester sur les instances les plus durs.\n",
    "\n",
    "On subdivise donc toutes les données en $K$ parts égales. A l'instant $k = 1,\\dots,K$, on isole la $k^{ième}$ part comme ensemble de test et on entraîne notre modèle sur les $K -1$ parties restantes. On obtient donc, $K$ score d'entraînement et de test. Dans le meilleur des cas, on tombe sur les instances qui donnent le plus de pouvoir de généralisation possible.\n",
    "\n",
    "Pour le SVM, avec juste les vecteurs supports, ce qui reprèsente moins de $10\\%$ de la donnée dans notre cas, on obtient le meilleur séparateur linéaire. En cas pratique, au moment de la validation, on aura jamais vu les instances à prédire. On n'est pas sûr donc de tomber sur les vecteurs supports du meilleur modèle qui résoud le problème. On cherche donc, grâce à la validation croisée, les points les plus proches de la marge; et ainsi, le meilleur pouvoir de généralisation.\n",
    "\n",
    "La généralisation passe aussi par le bon choix des paramètres du modèle. On utilise donc cette approche dans le but de trouver expérimentalement les meilleurs paramètres. Aussi, répète-t-on l'expérience afin d'essayer autant de configurations possibles. Les paramètres qui donnent les meilleurs scores de tests seront choisis au bout de l'étude.\n",
    "\n",
    "Le *test score* n'est pas la seule métrique possible. On peut chercher à maximiser le *F-score*. On peut aussi s'intéresser qu'au score d'une classe donnée:\n",
    "\n",
    "* Exemple: Vaudrait mieux un faux signal positif au scanner de bagage qu'un faux négatif (i.e. drogue ou explosif détectés comme sûrs).\n",
    "\n",
    "\n",
    "1. En utilisant la focntion [cross_validate](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) de scikit-learn, trouver la bonne valeur de $C$ pour un modèle SVM linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [pow(2, p) for p in range(-15, 15)]\n",
    "\n",
    "# choisir le K de répartition\n",
    "k = 5\n",
    "\n",
    "# tester avec tout les C dans Cs est stocker les scores\n",
    "test_scores = [None for C in Cs]\n",
    "\n",
    "# le meilleur C est ?\n",
    "C = None\n",
    "test_score = None\n",
    "print('Le meilleur paramètre de pénalisation des variables ressort est :', C, ', avec un test score de :', test_score)\n",
    "\n",
    "# Tracer le meilleur séparateur\n",
    "f, ax = plt.subplots(1, 1)\n",
    "f.set_figheight(10)\n",
    "f.set_figwidth(10)\n",
    "\n",
    "plot_dataset(X, Y, ax)\n",
    "xx, yy = mesh_from(X, .01)\n",
    "plot_margin(\n",
    "    xx,\n",
    "    yy,\n",
    "    ax,\n",
    "    model\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM vs Random Forest\n",
    "\n",
    "1. a. Comparer le meilleur kernel SVM trouver dans la section 'Kernel SVM' avec une forêt aléatoire de votre choix. \n",
    "\n",
    "   b. Tracer les courbes de séparation.\n",
    "\n",
    "   c. Justifier votre choix de nombre d'arbres et de profondeur.\n",
    "\n",
    "2. Commenter les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "X, Y = sklearn.datasets.make_circles(n_samples=100, factor=.3, noise=.05)\n",
    "\n",
    "f, ax = plt.subplots(1, 2)\n",
    "f.set_figheight(10)\n",
    "f.set_figwidth(20)\n",
    "\n",
    "plot_dataset(X, Y, ax)\n",
    "xx, yy = mesh_from(X, .01)\n",
    "plot_margin(\n",
    "    xx,\n",
    "    yy,\n",
    "    ax,\n",
    "    model\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection d'attribut\n",
    "\n",
    "### Occupation des sols\n",
    "\n",
    "L'occupation des sols à pour but de donner pour le type d'usage faits des terres. Naturellement, la manière la moins couteuse pour obtenir, à large échelle et à très grande fréquence, cette donnée, serait une approche automatique basée sur les images satellitaires.\n",
    "\n",
    "On cherche à assigner, pour chaque pixel, un des types possibles d'usage en partant de la valeur du pixel ou son voisinage. Le problème peut être résolu avec une méthode de classification.\n",
    "\n",
    "#### Présentation de la donnée\n",
    "\n",
    "Pour ce TP nous utilisons une image du satellite optique [Sentinel-2 du programme européen Copernicus](http://www.esa.int/Our_Activities/Observing_the_Earth/Copernicus/Sentinel-2) acquise le 10 juillet 2016 et téléchargée depuis la plateforme [Theia](https://theia.cnes.fr).\n",
    "\n",
    "10 des 13 bandes spectrales du satellite Sentinel-2 y sont disponibles en niveau de traitement 2A (B2, B3, B4, B5, B6, B7, B8, B8A, B11, B12). Ces 10 bandes spectrales ont été réchantillonnées en géométrie terrain (Lambert 93) à 10 m de résolution spatiale et assemblées dans le fichier *sentinel-2_sample.tif*.\n",
    "\n",
    "L'images *sentinel-2_sample.tif* concerne une zone de $14 km\\times14 km$ dans le département de la Haute-Garonne (31, ville de Saint-Gaudens).\n",
    "\n",
    "On dispose aussi de :\n",
    "* *RGE-OCS.shp* : un extrait de l’OCS GE de l’IGN sur la zone d’étude ainsi qu’un fichier décrivant;\n",
    "* *RGE-foret.shp* : un extrait de la BD Forêt de l’IGN sur la zone d’étude.\n",
    "\n",
    "A partir de ces données, on a la vérité terrain raster à la même échelle pour chaque pixel dans:\n",
    "* *ground_truth_landcover.tif*: vérité terrain OCS générale.\n",
    "* *ground_truth_forest.tif*: vérité terrain raster forêt-non forêt.\n",
    "\n",
    "\n",
    "1. a. Ouvrir le fichier projet *dataset.qgs* avec QGIS. \n",
    "\n",
    "   b. Etudier l'histogramme des bandes de l'image hyperspectrale et la vérité terrain.\n",
    "   \n",
    "   c. Qu'est-ce-que reprèsente chaque bande spectrale de l'image?\n",
    "\n",
    "2. a. Charger l'image sur python en se servant de *gdal*.\n",
    "\n",
    "   b. Ajouter le *NDVI* comme bande supplémentaire à votre donnée.\n",
    "    * Rappel: $$NDVI = \\frac{({\\mbox{NIR}}-{\\mbox{Red}})}{({\\mbox{NIR}}+{\\mbox{Red}})}$$\n",
    "\n",
    "   c. Séparer les pixels en données d'entraînement et données de validation à un ratio de 4/5.\n",
    "   \n",
    "   d. Utiliser la validation croisée pour trouver le meilleur kernel et les bons paramètres.\n",
    "   \n",
    "   e. Qualifier les résultats obtenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "import gdalconst\n",
    "\n",
    "def read(filename):\n",
    "    dataset = gdal.Open(filename, gdalconst.GA_ReadOnly)\n",
    "    return [dataset.GetRasterBand(band).ReadAsArray().astype(np.float) for band in dataset.RasterCount]\n",
    "\n",
    "def add_band(X, lhs, rhs):\n",
    "    # Compléter cette fonction afin qu'elle rajoute un nouveau canal à partir des deux bandes lhs et rhs\n",
    "    return \n",
    "\n",
    "# Répondre ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commentaires:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélections d'attributs:\n",
    "\n",
    "1. a. Estimer le nombre de toutes combinaisons possibles.\n",
    "   b. En utilisant les méthodes vues au cours (SVM-RFE, SFS , BFS et LR), établir une hiérarchie d'attributs (i.e. des bandes).\n",
    "2. Comparer les différentes méthodes.\n",
    "3. Commenter la hiérarchie obtenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_selection\n",
    "\n",
    "def add_best_L_attributes(X_selected, L, X, classifier):\n",
    "    # Compléter la fonction\n",
    "    return X_selected\n",
    "\n",
    "\n",
    "def remove_worst_R_attributes(X_selected, R, X, classifier):\n",
    "    # Compléter la fonction\n",
    "    return X_selected\n",
    "\n",
    "\n",
    "def sfs(X, classifier):\n",
    "    # Compléter la fonction\n",
    "    return\n",
    "\n",
    "\n",
    "def bfs(X, classifier):\n",
    "    # Compléter la fonction\n",
    "    return\n",
    "\n",
    "def lr(X, L, R, classifier):\n",
    "    # Compléter la fonction\n",
    "    return\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
