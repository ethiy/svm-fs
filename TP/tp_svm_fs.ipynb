{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM et Sélection d'attribut\n",
    "\n",
    "\n",
    "\n",
    "## Variables d'environement\n",
    "\n",
    "Pensez à vérifier les variables d'environement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation linéaire\n",
    "\n",
    "Le but de cette partie est de comparer le SVM linéaire à un autre exemple de classifieur linéaire: le Perceptron. On commence d'abords par rappeler rapidement le principe du Perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "L'algorithm du Perceptron date des [travaux de Frank Rosenblatt](http://psycnet.apa.org/record/1959-09865-001). Le but était de modéliser l'action des neurones. Ce modèle va être ensuite utilisé pour contruire des réseaux de neurones complexes et c'est la base de toute les méthodes de Deep Learning.\n",
    "\n",
    "Le modèle donne pour chaque attribut $i \\in \\{1,2, \\dots,d\\}$ de la donnée d'entrée $x = \\begin{pmatrix}x_1\\\\ x_2\\\\ \\vdots \\\\x_d\\end{pmatrix}$ un poids $w_i$. Pour chaque entrée $x$ on lui applique linéairement un vecteur de poids $w = \\begin{pmatrix}w_1\\\\ w_2\\\\ \\vdots \\\\w_d\\end{pmatrix}$ pour lui attribuer un score $s = \\langle w \\vert x\\rangle = \\sum_{i=1,\\dots,d}w_i.x_i$. Suite à ce score obtenu, on prends une décision:\n",
    "* si $s < c \\in \\mathbb{R}$, on choisit la classe $0$;\n",
    "* si $s \\geq c $, on choisit la classe $1$\n",
    "\n",
    "On peut écrire donc sa fonction de décision:\n",
    "\n",
    "$$D_{perceptron}(x) \\triangleq 2.\\mathbb{1}_{\\langle w \\vert x \\rangle + b \\geq 0} - 1 = sign(\\langle w \\vert x \\rangle + b)$$\n",
    "\n",
    "où $b = -c$ et $\\mathbb{1}_A(x) = \\begin{cases}1 & , x \\in A\\\\0 & , x \\notin A\\end{cases}$.\n",
    "\n",
    "Le modèle du Perceptron revient donc à choisir un modèle de séparation de donnée linéaire. C'est en réalité une fammille de séparateur possibles. Nous n'avons aucune garantie sur son pouvoir de généralisation.\n",
    "\n",
    "1. Qu'est ce qui différencie le SVM par rapport au Perceptron en terme de pouvoir de généralisation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réponse\n",
    "\n",
    "1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression logistique\n",
    "\n",
    "Le modèle de régression logistique est proche des méthodes génératives. Ce modèle donne une relation entre les probabilités des attributs sachant la classe, comme suit:\n",
    "$$ \\ln \\Big( \\frac{p(x \\vert y=1)}{p(x \\vert y=-1)}\\Big) = \\langle w \\vert x \\rangle + c \\quad , \\forall x $$\n",
    "\n",
    "2.\n",
    "    a. En appliquant la règle de Bayes, montrer que: \n",
    "    $$\\frac  {p(y=1\\vert x)}{p(y=-1\\vert x)} = \\frac{p(y=1)}{p(y=-1)} . \\frac{p(x \\vert y=1)}{p(x \\vert y=-1)}\\quad , \\forall x $$\n",
    "    b. En déduire la formule suivante:\n",
    "    $$\\ln\\Big(\\frac  {p(y=1\\vert x)}{1-p(y=1\\vert x)}\\Big) = \\ln\\Big(\\frac{p(y=1)}{p(y=-1)}\\Big) + c +\\langle w \\vert x \\rangle \\quad , \\forall x $$\n",
    "    c. On rappelle que $\\eta(x) = p(y=1\\vert x)$. Montrer que:\n",
    "$$\\eta(x) = \\sigma( b +\\langle w \\vert x \\rangle)$$\n",
    "où: $$\\sigma(t) \\triangleq \\frac{1}{1 + e^{-t}} \\quad ,\\forall t \\in \\mathbb{R}$$\n",
    "    d. Montrer que:\n",
    "    $$ sign(\\sigma(t) - \\frac{1}{2}) = sign(t)$$\n",
    "    On rappelle que:\n",
    "    $$sign(x) = 2.\\mathbb{1}_{x\\geq0} - 1 = 2. \\begin{cases}1 & , x\\geq0 \\\\ 0 &, x < 0 \\end{cases} - 1 = \\begin{cases}1 & , x \\geq 0 \\\\ -1 &, x < 0 \\end{cases}$$\n",
    "    $$$$\n",
    "    $$$$\n",
    "    On rappelle que, dans le cas binaire, la classe la plus probable $\\hat y = \\arg \\max_y p(y\\vert x)$ vérifie: \n",
    "    $$ p(\\hat y \\vert x) \\geq \\frac{1}{2} $$\n",
    "    En effet, puisque $y$ prend deux valeurs $1$ et $-1$, on peut écrire:\n",
    "    $$p(y \\vert x) + p(-y \\vert x) = 1$$\n",
    "    donc:\n",
    "    $$p(y \\vert x) \\geq \\frac{1}{2} \\Rightarrow p(-y \\vert x) = 1 - p(y \\vert x) \\leq 1 - \\frac{1}{2} = \\frac{1}{2} \\leq p(y \\vert x) \\Rightarrow p(y \\vert x) \\geq \\frac{1}{2} $$\n",
    "    Inversement, par définition:\n",
    "    $$p(\\hat y \\vert x) \\geq p( -\\hat y \\vert x) = 1 - p(\\hat y \\vert x) \\Rightarrow 2 . p(\\hat y \\vert x) \\geq 1 \\Rightarrow  p(\\hat y \\vert x) \\geq \\frac{1}{2} $$\n",
    "    On verifie donc bien que: \n",
    "    $$p(y \\vert x) \\geq \\frac{1}{2} \\Leftrightarrow y = \\hat y = \\arg \\max_y p(y \\vert x)$$\n",
    "    e. En déduire que la fonction de décision de Bayes pour le modèle logistique vérifie:\n",
    "    $$ D_{logistic} = sign(\\sigma( b +\\langle w \\vert x \\rangle) \\geq \\frac{1}{2}) = sign(b +\\langle w \\vert x \\rangle \\geq 0) = D_{perceptron}$$    \n",
    "    f. Qu'est ce que vérifie le séparateur dans un modèle logistique?\n",
    "\n",
    "3.\n",
    "    Ecrire un code python qui trace les deux fonctions, avec de multiple valeurs de $\\lambda$, $t \\mapsto \\sigma(\\lambda.t)$ et $t \\mapsto \\mathbb{1}_{t \\geq 0}$, dans une même figure. A la lumière de la figure obtenue, discuter les deux fonctions de décisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réponse\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x = np.linspace(-20, 20, 1000)\n",
    "\n",
    "lambdas = [.1, 1, 10]\n",
    "colors = ['k', 'b', 'r']\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison\n",
    "\n",
    "Le but du code, ci-dessous, est d'illustrer la différence entre le SVM, le Perceptron et la régression logistique.\n",
    "\n",
    "4.\n",
    "   a. Qu'est ce que fait ce bout de code?\n",
    "\n",
    "   b. Commentez le résultat du programme suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "\n",
    "\n",
    "def plot_points(points, ax, color):\n",
    "    ax.scatter(points[:, 0], points[:, 1], c=color)\n",
    "    \n",
    "\n",
    "def plot_dataset(X, Y, ax, colors=['r', 'b']):\n",
    "    for x, col in zip([X[Y==0], X[Y==1]], colors):\n",
    "        plot_points(x, ax, col)\n",
    "        \n",
    "\n",
    "def mesh_from(instances, gap=.2):\n",
    "    return np.meshgrid(\n",
    "        np.arange(X[:, 0].min() - 1, X[:, 0].max() + 1, gap),\n",
    "        np.arange(X[:, 1].min() - 1, X[:, 1].max() + 1, gap),\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_separator(xx, yy, ax, classifier, **parameters):\n",
    "    \"\"\"\n",
    "        Plots separator.\n",
    "        \n",
    "        xx: mesh first coordinates\n",
    "        yy: mesh second coordinates\n",
    "        ax: subplot to draw in\n",
    "        classifier: the trained classifier\n",
    "    \"\"\"\n",
    "    Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, **parameters)\n",
    "\n",
    "\n",
    "def plot_margin(xx, yy, ax, classifier, **parameters):\n",
    "    \"\"\"\n",
    "        Plots margins.\n",
    "        \n",
    "        xx: mesh first coordinates\n",
    "        yy: mesh second coordinates\n",
    "        ax: subplot to draw in\n",
    "        classifier: the trained classifier\n",
    "    \"\"\"\n",
    "    Z = np.empty(xx.shape)\n",
    "    for (i, j), value in np.ndenumerate(xx):\n",
    "        Z[i, j] = classifier.decision_function([[value, yy[i, j]]])[0]\n",
    "    ax.contour(xx, yy, Z, [-1.0, 0.0, 1.0], colors='k', linestyles=['dashed', 'solid', 'dashed'])\n",
    "\n",
    "\n",
    "X, Y = sklearn.datasets.make_blobs(n_samples=100, centers=2, random_state=0, cluster_std=0.60)\n",
    "xx, yy = mesh_from(X, .01)\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(15)\n",
    "\n",
    "for ax, loss , title in zip([ax1, ax2, ax3], ['hinge', 'perceptron', 'log'], ['SVM', 'Perceptron', 'Logistic Regression']):\n",
    "    plot_dataset(X, Y, ax)\n",
    "    model = sklearn.linear_model.SGDClassifier(alpha=0.01, max_iter=100, loss=loss).fit(X, Y)\n",
    "    plot_separator(\n",
    "        xx,\n",
    "        yy,\n",
    "        ax,\n",
    "        model,\n",
    "        cmap=plt.cm.viridis,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    plot_margin(\n",
    "        xx,\n",
    "        yy,\n",
    "        ax,\n",
    "        model\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réponse:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pénalisation vs Généralisation\n",
    "\n",
    "5.\n",
    "   a. Entraîner des SVM linéaire avec différentes constantes de pénalisation $C$ sur les mêmes données.\n",
    "\n",
    "   b. Tracer la marge selon les valeurs de la constante $C$.\n",
    "   \n",
    "   c. Commenter les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm\n",
    "\n",
    "Cs = [.01, .1, .5, 1, 10, 100, 1000]\n",
    "\n",
    "f, axes = plt.subplots(1, len(Cs), sharey=True)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(5 * len(Cs))\n",
    "\n",
    "for C, ax in zip(Cs, list(axes)):\n",
    "    plot_dataset(X, Y, ax)\n",
    "    model = sklearn.svm.SVC(C=C, kernel='linear').fit(X, Y)\n",
    "    plot_separator(\n",
    "        xx,\n",
    "        yy,\n",
    "        ax,\n",
    "        model,\n",
    "        cmap=plt.cm.viridis,\n",
    "        alpha=0.5\n",
    "    )\n",
    "    plot_margin(\n",
    "        xx,\n",
    "        yy,\n",
    "        ax,\n",
    "        model\n",
    "    )\n",
    "    ax.set_title('C = ' + str(C))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réponse:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SVM\n",
    "\n",
    "6.\n",
    "   a. Entraîner le SVM, en choisissant la meilleur valeur pour $C$, avec le kernel polynomial et le kernel rbf en jouant sur le $\\gamma$ sur les données suivantes.\n",
    "\n",
    "   b. Commenter les résultats.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = sklearn.datasets.make_circles(n_samples=100, factor=.3, noise=.05)\n",
    "xx, yy = mesh_from(X, .01)\n",
    "\n",
    "gammas = [1, 2, 3, 4, 5, 6]\n",
    "f, axes = plt.subplots(2, len(gammas), sharey=True)\n",
    "f.set_figheight(20)\n",
    "f.set_figwidth(10*len(gammas))\n",
    "\n",
    "for gamma, ax in zip(gammas, list(axes[0, :])):\n",
    "    plot_dataset(X, Y, ax)\n",
    "    \n",
    "    ax.set_title('Kernel polynômial, $\\gamma$ = ' + str(gamma))\n",
    "\n",
    "\n",
    "gammas = [.01, .1, 2, 10, 100, 1000]\n",
    "for gamma, ax in zip(gammas, list(axes[1, :])):\n",
    "    plot_dataset(X, Y, ax)\n",
    "    \n",
    "    ax.set_title('Kernel rbf, $\\gamma$ = ' + str(gamma))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réponse:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation croisée\n",
    "\n",
    "### Train-Test split\n",
    "\n",
    "Afin d'estimer le pouvoir de généralisation d'un classifieur, il faut le tester sur de nouvelles instances. On parle de données d'entraînement et données de tests. En pratique, on garde aussi des données de côtés pour la validation après calibrage entre entraînement et tests.\n",
    "\n",
    "1. a. En utilisant la fonction [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) fournie par scikit-learn, entraîner un SVM linéaire sur 80% de vos données et tester sur le reste.\n",
    "\n",
    "   b. Répéter l'experience plusieurs fois. Commenter les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "X, Y = sklearn.datasets.make_blobs(n_samples=200, centers=2, random_state=0, cluster_std=1.5)\n",
    "\n",
    "# Répartir les données en 4/5 de train data et 1/5 de test data\n",
    "\n",
    "# Entraîner le modèle\n",
    "\n",
    "# Tester le modèle entraîné\n",
    "\n",
    "f, ax = plt.subplots(1, 1)\n",
    "f.set_figheight(10)\n",
    "f.set_figwidth(10)\n",
    "\n",
    "plot_dataset(X_train, Y_train, ax)\n",
    "plot_dataset(X_test, Y_test, ax, ['y', 'g'])\n",
    "xx, yy = mesh_from(X, .01)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche de paramètres\n",
    "\n",
    "L'idée de la validation croisée et que l'on varie les données d'entraînement et de test, de façon à ne pas entraîner sur les mauvaises instances et puis tester sur les instances les plus durs.\n",
    "\n",
    "On subdivise donc toutes les données en $K$ parts égales. A l'instant $k = 1,\\dots,K$, on isole la $k^{ième}$ part comme ensemble de test et on entraîne notre modèle sur les $K -1$ parties restantes. On obtient donc, $K$ score de test. Dans le meilleur des cas, on tombe sur les instances qui donnent le plus de pouvoir de généralisation possible.\n",
    "\n",
    "Pour le SVM, avec juste les vecteurs supports, ce qui reprèsente moins de $10\\%$ de la donnée dans notre cas, on obtient le meilleur séparateur linéaire. En cas pratique, au moment de la validation, on ne connaît pas les instances à prédire. On n'est pas sûr donc de tomber sur les vecteurs supports du meilleur modèle qui résoud le problème. On cherche donc, grâce à la validation croisée, les points les plus proches de la marge; pour avoir ainsi, le meilleur pouvoir de généralisation.\n",
    "\n",
    "La généralisation passe aussi par le bon choix des paramètres du modèle. On utilise donc cette approche dans le but de trouver expérimentalement les meilleurs paramètres. Aussi, répète-t-on l'expérience afin d'essayer autant de configurations possibles. Les paramètres qui donnent les meilleurs scores de tests seront choisis au bout de l'étude.\n",
    "\n",
    "Le *test score* n'est pas la seule métrique possible. On peut chercher à maximiser le *F-score*, comme on peut aussi s'intéresser qu'au score d'une classe donnée:\n",
    "\n",
    "* Exemple: Vaudrait mieux un faux signal positif au scanner de bagage qu'un faux négatif (i.e. drogue ou explosif détectés comme sûrs ou un test sangui négatif pour un patient malade).\n",
    "\n",
    "\n",
    "7.\n",
    "    En utilisant la fonction [cross_validate](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) de scikit-learn, trouver la bonne valeur de $C$ pour un modèle SVM linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_metrics(scores):\n",
    "    return  (\n",
    "                np.max(scores),\n",
    "                np.mean(scores),\n",
    "                np.median(scores),\n",
    "                np.min(scores)\n",
    "            )\n",
    "\n",
    "Cs = [pow(2, p) for p in range(-15, 15)]\n",
    "\n",
    "# tester avec tout les C dans Cs est stocker les scores\n",
    "cv_scores = []\n",
    "test_scores = [cv_metrics(scores['test_score']) for scores in cv_scores]\n",
    "\n",
    "# le meilleur C est:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM vs Random Forest\n",
    "\n",
    "8.\n",
    "   a. Comparer le meilleur kernel SVM trouver dans la section 'Kernel SVM' avec une forêt aléatoire de votre choix. \n",
    "\n",
    "   b. Tracer les courbes de séparation.\n",
    "\n",
    "   c. Justifier votre choix de nombre d'arbres et de profondeur.\n",
    "\n",
    "9.\n",
    "    Commenter les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "import sklearn.tree\n",
    "\n",
    "X, Y = sklearn.datasets.make_circles(n_samples=100, factor=.3, noise=.05)\n",
    "xx, yy = mesh_from(X, .01)\n",
    "\n",
    "models = []\n",
    "\n",
    "titles=[\n",
    "    'Quadratic polynomial kernel SVM',\n",
    "    'RBF kernel SVM with $\\gamma = 2$',\n",
    "    'Decision Tree, i.e. n_trees = 1',\n",
    "    'Random Forest, n_trees = 1000, max_depth = 1',\n",
    "    'Random Forest, n_trees = 1000, max_depth = 2',\n",
    "    'Random Forest, n_trees = 1000, max_depth = 4',\n",
    "    'Random Forest, n_trees = 1000'\n",
    "]\n",
    "\n",
    "f, axes = plt.subplots(1, len(models))\n",
    "f.set_figheight(10)\n",
    "f.set_figwidth(10*len(models))\n",
    "\n",
    "for model, ax, title in zip(models, axes, titles):\n",
    "    plot_dataset(X, Y, ax)\n",
    "    \n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réponse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection d'attribut\n",
    "\n",
    "### Occupation des sols\n",
    "\n",
    "L'occupation des sols à pour but de donner pour le type d'usage faits des terres. Naturellement, la manière la moins couteuse pour obtenir, à large échelle et à très grande fréquence, cette information, serait une approche automatique basée sur les images satellitaires.\n",
    "\n",
    "On cherche à assigner, pour chaque pixel, un des types d'usage possibles, en utilisant la valeur du pixel ou son voisinage. On modèlise donc le problème avec classification supervisée.\n",
    "\n",
    "#### Présentation de la donnée\n",
    "\n",
    "Pour ce TP nous utilisons une image du satellite optique [Sentinel-2 du programme européen Copernicus](http://www.esa.int/Our_Activities/Observing_the_Earth/Copernicus/Sentinel-2). Cette image est acquise le 10 juillet 2016 et téléchargée depuis la plateforme [Theia](https://theia.cnes.fr).\n",
    "\n",
    "10, des 13 bandes spectrales du satellite Sentinel-2, y sont disponibles en niveau de traitement 2A: B2, B3, B4, B5, B6, B7, B8, B8A, B11 et B12. Ces 10 bandes spectrales ont été réchantillonnées en géométrie terrain (Lambert 93) à 10 m de résolution spatiale et assemblées dans le fichier `sentinel-2_sample.tif`.\n",
    "\n",
    "Les bandes spectrales de *Sentinel 2*:\n",
    "![Les bandes spectrales de *Sentinel 2*][sentinel_2]\n",
    "\n",
    "L'image `sentinel-2_sample.tif` concerne une zone de $14$ Km $\\times14$ Km dans le département de la Haute-Garonne (31): ville de Saint-Gaudens. Toutes les données se trouvent dans le répértoire `./data`.\n",
    "\n",
    "On dispose aussi de :\n",
    "* `RGE-OCS.shp` : un extrait de l’OCS GE (**OC**cupation du **S**ol **G**rande **E**chelle) de l’IGN sur la zone d’étude;\n",
    "* `RGE-foret.shp` : un extrait de la BD Forêt de l’IGN sur la zone d’étude.\n",
    "\n",
    "A partir de ces données, on obtient la vérité terrain *raster* à la même échelle pour chaque pixel dans:\n",
    "* `ground_truth_landcover.tif`: vérité terrain OCS générale.\n",
    "* `ground_truth_forest.tif`: vérité terrain raster forêt-non forêt.\n",
    "\n",
    "\n",
    "1. a. Ouvrir le fichier projet `dataset.qgs` avec QGIS. \n",
    "\n",
    "   b. Etudier l'histogramme des bandes de l'image hyperspectrale et la vérité terrain.\n",
    "   \n",
    "   c. En se basant sur la description des bandes [ici](https://sentinel.esa.int/web/sentinel/missions/sentinel-2/instrument-payload/resolution-and-swath), trouver les correspondances entre des canals de l'image et les bandes spectrales de Sentinel 2?\n",
    "\n",
    "2. a. Charger l'image sur python en se servant de *gdal*.\n",
    "\n",
    "   b. Ajouter le *NDVI* comme bande supplémentaire à votre donnée.\n",
    "   \n",
    "     * Rappel: $$NDVI = \\frac{{\\text{NIR}}-{\\text{Red}}}{{\\text{NIR}}+{\\text{Red}}}$$\n",
    "     * Astuce: ajouter un $\\epsilon$ pour ne pas diviser sur zéro. $$NDVI = \\frac{{\\text{NIR}}-{\\text{Red}}}{{\\text{NIR}}+{\\text{Red}}+\\epsilon}$$\n",
    "\n",
    "   c. Séparer les pixels en données d'entraînement et données de validation à un ratio de 4/5.\n",
    "   \n",
    "   d. Utiliser la validation croisée pour trouver le meilleur kernel et les bons paramètres de votre SVM.\n",
    "   \n",
    "   e. Qualifier les résultats obtenus.\n",
    "\n",
    "[sentinel_2]: http://www.cesbio.ups-tlse.fr/data_all/images/sentinel1.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "import gdalconst\n",
    "\n",
    "def read(filename):\n",
    "    \"\"\"\n",
    "        reads all bands of raster images.\n",
    "        \n",
    "        :param filename: the path to the raster image\n",
    "        :type filename: string\n",
    "        :return: a list containing a numpy matrix for each band\n",
    "        :rtype: list\n",
    "    \"\"\"\n",
    "    dataset = gdal.Open(filename, gdalconst.GA_ReadOnly)\n",
    "    return [\n",
    "        dataset.GetRasterBand(band).ReadAsArray().astype(np.float64)\n",
    "        for band in range(1, dataset.RasterCount + 1)\n",
    "    ]\n",
    "\n",
    "\n",
    "def add_band(image, lhs, rhs, func):\n",
    "    \"\"\"\n",
    "        add a band to an image by applying a function on two of the image bands.\n",
    "        \n",
    "        :param image: a list containing the image bands.\n",
    "        :param lhs: index of the first band to use\n",
    "        :param rhs: index of the second band to use\n",
    "        :param func: the function to apply on the two bands\n",
    "        :type image: list\n",
    "        :type lhs: int\n",
    "        :type rhs: int\n",
    "        :type func: function\n",
    "        :return: a list containing a numpy matrix for each band\n",
    "        :rtype: list\n",
    "    \"\"\"\n",
    "    return image.append(func(image[lhs], image[rhs]))\n",
    "\n",
    "\n",
    "def add_ndvi(image):\n",
    "    # Utiliser add_band\n",
    "    return image\n",
    "\n",
    "\n",
    "band_names = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11' , 'B12']\n",
    "bands = read('./data/sentinel-2_sample.tif')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Réponses:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélections d'attributs:\n",
    "\n",
    "1. a. Estimer le nombre de toutes combinaisons d'attributs possibles.\n",
    "\n",
    "   b. En utilisant les méthodes vues au cours (SVM-RFE, SFS , BFS et LR), établir une hiérarchie d'attributs (i.e. des bandes).\n",
    "2. Comparer les différentes méthodes.\n",
    "3. Commenter les hiérarchies obtenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_selection\n",
    "\n",
    "def add_best_L_attributes(X_selected, L, X, classifier):\n",
    "    # Compléter la fonction\n",
    "    return X_selected\n",
    "\n",
    "\n",
    "def remove_worst_R_attributes(X_selected, R, X, classifier):\n",
    "    # Compléter la fonction\n",
    "    return X_selected\n",
    "\n",
    "\n",
    "def sfs(X, classifier):\n",
    "    # Compléter la fonction\n",
    "    return\n",
    "\n",
    "\n",
    "def bfs(X, classifier):\n",
    "    # Compléter la fonction\n",
    "    return\n",
    "\n",
    "def lr(X, L, R, classifier):\n",
    "    # Compléter la fonction\n",
    "    return\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
